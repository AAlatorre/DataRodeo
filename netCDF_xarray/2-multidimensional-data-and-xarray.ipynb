{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 0,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "# Using `xarray` to work with multi-dimensional data\n",
    "\n",
    "As we saw in the last notebook, it is possible to work with multidimensional netCDF data in Pandas, but it's a bit cumbersome in that we have to inspect variables and occasionally have to reassign and/or convert their units into more meaningful ones, often going back and forth between the `netCDF4` and `Pandas` (and sometimes the `numpy`) packages. A new-ish Python package called `xarray` (http://xarray.pydata.org/en/stable/) streamlines all that and is much more pleasant to use with netCDF data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 5,
        "hidden": false,
        "row": 5,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "Here, we use the same dataset as in the previous notebook: downscaled monthly runoff data at a 1/8th degree spatial resolution. We'll see how the `xarray` package can easily read in these data in their netCDF format and use actual axes values (e.g. a date and lat/long coordinate pair to identify values instead of row, column, etc. values). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from urllib import request\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 10,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "### Load the data into an xarray dataset object\n",
    "First, we load the netCDF `.nc` file into an xarray **dataset** object. (See the previous notebook for code to download the file if you don't have the dataset file in the data folder.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 10,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the runoff data into an xarray dataset object\n",
    "ds = xr.open_dataset('../data/conus_c5.ccsm4_rcp26_r1i1p1.monthly.total_runoff.2000.nc')\n",
    "type(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calling the Dataset objet reveals information about what it contains\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the variables\n",
    "The dataset object's `variables` function returns a dictionary of variable objects. We can list the keys associated with this dictionary to show what variables the dataset contains. And then look at the value of a select variable to see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reveal the variables in the dataset\n",
    "ds.variables.mapping.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Examine \"time\" variable; see that it is a 1D array (vector) with 12 values\n",
    "ds['time'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now you try it**: Examine the other variables. How what is the shape of the `latitude` variable? the `total_runoff` variable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds['total_runoff']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save a variable's contents into an xarray `DataArray` object\n",
    "Saving a variable to an object creates a DataArray object, with which we can examine and work with. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Save the runoff variable into a single data array\n",
    "arrRunoff = ds['total_runoff']\n",
    "type(arrRunoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 9,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Display information about the arrRunoff data array\n",
    "print(arrRunoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the time dimension from the data array\n",
    "arrTime = arrRunoff.time\n",
    "type(arrTime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arrTime2 = ds['time']\n",
    "type(arrTime2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 5,
        "hidden": false,
        "row": 14,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Display the first 5 records of the arrTime data array\n",
    "arrTime[:5].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*In the above, note that the time is already converted to actual time, not to \"days since 1900\" as in the NetCDF notebook example*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the lat and long values into separate DataArrays\n",
    "arrLat = arrRunoff.latitude\n",
    "arrLon = arrRunoff.longitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 19,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Display the extents of the data\n",
    "print(\"Time:\",arrTime.data.min(),arrTime.data.max())\n",
    "print(\"Lat: \",arrLat.data.min(),arrLat.data.max())\n",
    "print(\"Lon: \",arrLon.data.min(),arrLon.data.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Show example lat/long values\n",
    "arrLat[30].data,arrLon[30].data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 27,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Extract data for one time-location combination\n",
    "Use the xarray dataset's `sel` function to select the runoff value nearest the specified time and location. This is *much* easier than in the previous notebook where we tried using NumPy and Pandas since Xarray knows how to link the real values (e.g. data, degrees north or east) with index locations... Also the `nearest` function allows us to use time/location coordinates that approximate values that exist in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Set the time and location coordinates for where we want to get a value\n",
    "theTime = np.datetime64('2000-03-15')\n",
    "theLat = 36.005\n",
    "theLon = -78.942"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the value corresponding to the point nearest to the specified time & location\n",
    "theResult = ds.sel(latitude=theLat,longitude=theLon,time=theTime,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Show the runoff at that point\n",
    "theResult.total_runoff.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Now you try it**: see if you can find the runoff estimate for St. Louis on October 4, 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find the runoff estimate for a given time and location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 31,
        "width": 12
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Plot a time series for one location\n",
    "Dropping one of the dimensions in the `sel` statement retrieves all data in that dimension fitting the criteria specified in the other dimensions. Here, we omit the time constraint."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Select only on lat and lon and we get all runoff data for all times\n",
    "theTimeSeries = ds.sel(latitude=theLat,longitude=theLon,method='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the precipitation data array from the filtered dataset\n",
    "ts_Runoff = theTimeSeries.total_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 6,
        "hidden": false,
        "row": 35,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Plot the time series\n",
    "fig = plt.figure(figsize=(15,5))\n",
    "ts_Runoff.plot.line();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that plotting an xarray data array gives nice axis labels and titles by default!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 23,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Map runof for one time period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Drop the lat and lon filters to grab data for all locations\n",
    "theMapResult = ds.sel(time=theTime).total_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 7,
        "hidden": false,
        "row": 35,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Plot the data\n",
    "fig = plt.figure(figsize=(12,5))\n",
    "theMapResult.plot(cmap=\"YlGnBu\", #Specifies the colors to use\n",
    "                  robust=True);  #Drops outliers (<2%,>98%) from plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 35,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Create a spatial subset\n",
    "We uses \"slices\" to extract subsets of data. Here we subset the data spatially and compute the mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Specify the spatial slices to grab\n",
    "theLats = slice(25,36.5)\n",
    "theLons = slice(-91,-76)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract the spatial subset into its own data array\n",
    "theSubset = ds.sel(longitude=theLons,latitude=theLats).total_runoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 39,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Display the shape of the returned data array\n",
    "theSubset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 9,
        "hidden": false,
        "row": 41,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Plot a histogram of the data within the subset\n",
    "theSubset.plot(bins=20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 4,
        "height": 9,
        "hidden": false,
        "row": 42,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Compute the mean across the time axis (the 0th axis) and show a map\n",
    "theSubsetAvg = theSubset.mean(axis=0)\n",
    "theSubsetAvg.plot(cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 43,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Fancier plots\n",
    "#Create the canvas\n",
    "plt.figure(figsize=(15,3)) \n",
    "#In the first of a 1x3 set of subplots, plot the min across all samples at each location\n",
    "plt.subplot(1,3,1)\n",
    "theSubset.min(axis=0).plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Min\")\n",
    "#In the second of a 1x3 set of subplots, plot the mean\n",
    "plt.subplot(1,3,2)\n",
    "theSubset.mean(axis=0).plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Mean\")\n",
    "#In the third of a 1x3 set of subplots, plot the max\n",
    "plt.subplot(1,3,3)\n",
    "theSubset.max(axis=0).plot(cmap=\"YlGnBu\")\n",
    "plt.title(\"Max\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 4,
        "hidden": false,
        "row": 47,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "source": [
    "## Calculate summer (JJA) average\n",
    "The `xarray` package supports seasons to make easy seasonal averages. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Create a new data array by converting the dates in the `time` array to seasons\n",
    "arrSeason = ds['time'].dt.season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "hidden": true
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Replace the time dimension with season values\n",
    "ds['time'] = ds['time'].dt.season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 0,
        "height": 4,
        "hidden": false,
        "row": 50,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Extract precipitation for just the summer months; we have 48 summers of data\n",
    "summerRunoff = ds.sel(time='JJA',latitude=theLats,longitude=theLons).total_runoff\n",
    "summerRunoff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reduce the three selected months into one summer average and plot it\n",
    "meanSummerRunoff = summerRunoff.mean(axis=0)\n",
    "meanSummerRunoff.plot(cmap=\"YlGnBu\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "extensions": {
     "jupyter_dashboards": {
      "version": 1,
      "views": {
       "grid_default": {
        "col": 8,
        "height": 5,
        "hidden": false,
        "row": 51,
        "width": 4
       },
       "report_default": {}
      }
     }
    }
   },
   "outputs": [],
   "source": [
    "#Fancier plots\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.subplot(1,2,1)\n",
    "summerPrecip.mean(axis=0).plot(cmap=\"YlGnBu\")\n",
    "plt.subplot(1,2,2)\n",
    "summerPrecip.std(axis=0).plot(cmap=\"YlGnBu\")\n",
    "#plt.subplot(1,3,3)\n",
    "#summerPrecip.max(axis=0).plot(cmap=\"YlGnBu\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Recap\n",
    "With more an more groups providing data in multi-dimensional netCDF format, it's useful to know how to wrangle these data to get what you want. We saw before that the Python `netCDF4` package, along with `NumPy` and `Pandas` does give us control over these datasets, but here we see that developers are constantly making our lives a touch easier by developing packages that just make things easier. **Still**, it's alway good to at least once struggle through data with the basic packages as it gives us a more intimate working knowledge of how the data are strucutred and what exactly is going on behind the scenes of these newer packages "
   ]
  }
 ],
 "metadata": {
  "extensions": {
   "jupyter_dashboards": {
    "activeView": "grid_default",
    "version": 1,
    "views": {
     "grid_default": {
      "cellMargin": 10,
      "defaultCellHeight": 20,
      "maxColumns": 12,
      "name": "grid",
      "type": "grid"
     },
     "report_default": {
      "name": "report",
      "type": "report"
     }
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
